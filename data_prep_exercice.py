# -*- coding: utf-8 -*-
"""DATA PREP EXERCICE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FmOH1wsh8v4b_gTLNims0HgWhCahw35E

**Data preparation**
*
"""

import pandas as pd
import numpy as np
import seaborn as sns

url = "https://covid.ourworldindata.org/data/owid-covid-data.csv"
 df = pd.read_csv(url)
 df.head(6)

"""GET TO KNOW DATA"""

df.describe()

#shape my dataset
df.shape

#check duplicated handling duplicates
df.duplicated().sum()
#if we had duplicate in this data , this is how we were going to handle them
df.drop_duplicates(inplace=True)

"""Handling Null values"""

#check null values
df.isnull().sum()

df.dropna(inplace=True)
dfl = df.dropna(subset = ['total_cases'])

"""imputation"""

#numerical values
#using mean
df['total_cases'] = df['total_cases'].fillna(df['total_cases'].mean())
#using median
df['total_cases']= df['total_cases'].fillna(df['total_cases'].median())

#categorical values
df['location'] = df['location'].fillna(df['location'].mode())

"""**DROPPING COLUMNS**"""

#drop column called iso_code
df.drop('iso_code', axis=1, inplace=True)
#now write code to drop column named new_deaths_smoothed
df.drop('new_deaths_smoothed', axis=1, inplace=True)

"""**Getting a Subset of your Data**"""

#get subset of your data for zimbabwe and rwanda
subset= df[(df['location'] == 'Zimbabwe') |(df['location'] =='Rwanda')]
#display the subset
subset.head()

"""**Let's save our cleaned Data**"""

#save the  data you have cleaned
df.to_csv('url', index=False)